# BioMistral Clinical Assistant

Assistant m√©dical bas√© sur BioMistral-7B fine-tun√© pour l'aide √† la prescription d'imagerie c√©r√©brale selon les guidelines HAS/SFETD 2017.

##  Fonctionnalit√©s

- **RAG (Retrieval-Augmented Generation)** : Interroge une base de directives m√©dicales
- **Format structur√©** : Sorties `Pour pr√©ciser:` ou `Recommandation:`
- **Fine-tuning sp√©cialis√©** : 200 cas cliniques (c√©phal√©es, red flags, grossesse, traumatisme)
- **Mod√®le quantifi√© Q8_0** : Balance qualit√©/performance pour d√©ploiement Ollama

##  Structure du projet

```
v_llm/
‚îú‚îÄ‚îÄ src/                    # Code source principal
‚îÇ   ‚îú‚îÄ‚îÄ main.py            # CLI interactive
‚îÇ   ‚îú‚îÄ‚îÄ ollama.py          # Interface Ollama + RAG
‚îÇ   ‚îî‚îÄ‚îÄ indexage.py        # Indexation ChromaDB
‚îÇ
‚îú‚îÄ‚îÄ data/                   # Donn√©es et guidelines
‚îÇ   ‚îú‚îÄ‚îÄ guidelines.json    # Directives m√©dicales
‚îÇ   ‚îú‚îÄ‚îÄ clinical_cases_train.jsonl  # 160 cas d'entra√Ænement
‚îÇ   ‚îî‚îÄ‚îÄ clinical_cases_val.jsonl    # 40 cas de validation
‚îÇ
‚îú‚îÄ‚îÄ training/               # Pipeline d'entra√Ænement
‚îÇ   ‚îú‚îÄ‚îÄ generate_finetune_dataset.py    # G√©n√©ration dataset
‚îÇ   ‚îú‚îÄ‚îÄ finetune_biomistral_unsloth.py  # Fine-tuning (Colab)
‚îÇ   ‚îú‚îÄ‚îÄ merge_biomistral.py             # Merge LoRA
‚îÇ   ‚îî‚îÄ‚îÄ convert-hf-to-gguf.py           # Conversion GGUF
‚îÇ
‚îú‚îÄ‚îÄ models/                 # Mod√®les finaux
‚îÇ   ‚îú‚îÄ‚îÄ biomistral_clinical_lora_v2/           # Adapters LoRA
‚îÇ   ‚îú‚îÄ‚îÄ biomistral_clinical_lora_v2_merged/    # Mod√®le HF merg√©
‚îÇ   ‚îî‚îÄ‚îÄ biomistral_clinical_lora_v2_merged-q8_0.gguf  # GGUF production
‚îÇ
‚îú‚îÄ‚îÄ evaluation/             # √âvaluation
‚îÇ   ‚îî‚îÄ‚îÄ evaluate_model.py  # Script d'√©valuation automatique
‚îÇ
‚îú‚îÄ‚îÄ docs/                   # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ CLEANUP_REPORT.md
‚îÇ   ‚îî‚îÄ‚îÄ CLEANUP_SUMMARY.md
‚îÇ
‚îú‚îÄ‚îÄ gguf-py/               # Biblioth√®que GGUF
‚îÇ
‚îú‚îÄ‚îÄ Modelfile              # Configuration Ollama
‚îú‚îÄ‚îÄ requirements.txt       # D√©pendances Python
‚îú‚îÄ‚îÄ run_cli.sh            #  Lancer l'interface CLI
‚îú‚îÄ‚îÄ run_evaluation.sh     #  Lancer l'√©valuation
‚îî‚îÄ‚îÄ .gitignore
```

##  D√©marrage rapide

### 1. Installation

```bash
# Installer les d√©pendances
pip install -r requirements.txt

# Cr√©er le mod√®le Ollama
ollama create biomistral-clinical -f Modelfile

# V√©rifier que le mod√®le est disponible
ollama list | grep biomistral
```

### 2. Utilisation

#### Interface CLI interactive
```bash
./run_cli.sh
# ou
python src/main.py
```

**Exemple d'utilisation :**
```
M√©decin: Patient 45 ans, c√©phal√©es

BioMistral: Pour pr√©ciser: Depuis quand et quel caract√®re ont les c√©phal√©es 
(brutale / intense / progressive) ? | Y a‚Äët‚Äëil fi√®vre, vomissements, perte 
de connaissance, convulsions ou d√©ficit neurologique focal ? | La patiente 
est‚Äëelle enceinte, a‚Äët‚Äëelle des ant√©c√©dents majeurs (cancer, immunod√©pression) 
ou un traumatisme cr√¢nien r√©cent ?

M√©decin: progressive depuis 3 semaines

BioMistral: Recommandation: Pas d'imagerie en premi√®re intention si absence 
de signes d'alerte; traitement symptomatique et suivi ambulatoire. Refaire 
une √©valuation si persistance/majoration.
```

#### √âvaluation
```bash
# √âvaluer sur 5 cas
./run_evaluation.sh --limit 5

# √âvaluation compl√®te (40 cas)
./run_evaluation.sh
```

#### Test direct
```bash
ollama run biomistral-clinical "Patient 55 ans, c√©phal√©es brutales depuis 2h"
```

##  Workflow d'entra√Ænement

### 1. G√©n√©ration du dataset
```bash
cd training
python generate_finetune_dataset.py --n 200
# Produit: ../data/clinical_cases_train.jsonl (160 cas)
#         ../data/clinical_cases_val.jsonl (40 cas)
```

### 2. Fine-tuning (Colab recommand√©)
```bash
# Sur Colab avec GPU T4/A100
python finetune_biomistral_unsloth.py \
    --model_name BioMistral/BioMistral-7B \
    --train_file ../data/clinical_cases_train.jsonl \
    --val_file ../data/clinical_cases_val.jsonl \
    --output_dir ../models/biomistral_clinical_lora_v2 \
    --num_train_epochs 3 \
    --batch_size 2
```

### 3. Merge des adapters LoRA
```bash
python merge_biomistral.py
# Produit: ../models/biomistral_clinical_lora_v2_merged/
```

### 4. Conversion GGUF
```bash
python convert-hf-to-gguf.py \
    ../models/biomistral_clinical_lora_v2_merged/ \
    --outfile ../models/biomistral_clinical_lora_v2_merged-q8_0.gguf \
    --outtype q8_0
```

### 5. Cr√©ation du mod√®le Ollama
```bash
cd ..
ollama create biomistral-clinical -f Modelfile
```

##  M√©triques d'√©valuation

Le script `evaluate_model.py` calcule :
- **Format compliance** : % de sorties respectant le format attendu
- **Pr√©cision de classe** : % de recommandations correctes (clarify/urgent/non-urgent/no imaging)
- **Urgence precision/recall** : M√©triques sp√©cifiques aux cas urgents (red flags)

### Exemple de rapport
```
Cas √©valu√©s : 40
Format conforme : 95.0% (38/40)
Pr√©cision de classe : 72.5% (29/40)
Urgence ‚Äì pr√©cision : 85.7% (TP=6, pr√©dits=7)
Urgence ‚Äì rappel : 75.0% (positifs r√©els=8)
```

##  Configuration

### Modelfile (Ollama)
```
FROM ./models/biomistral_clinical_lora_v2_merged-q8_0.gguf

PARAMETER temperature 0.0
PARAMETER top_p 0.9
PARAMETER num_ctx 4096

SYSTEM """Tu es un assistant m√©dical expert..."""
```

### Prompt syst√®me
Le prompt dans `src/ollama.py` force :
1. V√©rification syst√©matique des signes d'alerte
2. Questions standardis√©es si info manquante
3. Format strict `Pour pr√©ciser:` / `Recommandation:`
4. Justification bas√©e sur les guidelines RAG

##  Guidelines m√©dicales

Le fichier `data/guidelines.json` contient :
- Crit√®res d'imagerie urgente (HAS/SFETD 2017)
- Red flags : c√©phal√©e brutale, d√©ficit neuro, fi√®vre, convulsions, perte de connaissance
- Cas sp√©cifiques : grossesse, immunod√©pression, traumatisme, √¢ge >50 ans
- Protocoles d'imagerie : IRM vs Scanner, avec/sans injection, d√©lai

## üõ†Ô∏è D√©veloppement

### Ajouter des guidelines
```json
{
  "id": "guideline_10",
  "motif": "Nouveau contexte",
  "texte": "Description de la directive...",
  "source": "R√©f√©rence m√©dicale"
}
```

### Modifier le prompt syst√®me
√âditer `src/ollama.py`, fonction `rag_biomistral_query()`, variable `prompt`.

### Simplifier la logique CLI
Si le mod√®le fine-tun√© g√®re bien les clarifications, simplifier `src/main.py` lignes 40-100.

##  D√©pendances principales

```
transformers>=4.57.0
peft>=0.17.0
unsloth
torch>=2.9.0
chromadb
ollama
gguf-py (local)
```

##  Notes importantes

1. **Mod√®le de base** : BioMistral-7B doit √™tre t√©l√©charg√© s√©par√©ment (~14 GB)
2. **Fine-tuning** : N√©cessite GPU (Colab recommand√©, T4 minimum)
3. **Ollama** : Le mod√®le `biomistral-clinical:latest` doit √™tre cr√©√© localement
4. **ChromaDB** : Base RAG reconstruite √† chaque lancement (pas de persistance)

##  Debugging

### Le mod√®le ne respecte pas le format
- V√©rifier la temp√©rature (doit √™tre 0.0 pour d√©terminisme)
- Relancer avec `./run_evaluation.sh --limit 1` pour tester

### Erreur "Model not found"
```bash
ollama list
# Si absent :
ollama create biomistral-clinical -f Modelfile
```

### Erreur de chemin
Tous les scripts utilisent des chemins relatifs depuis leur position.  
Toujours lancer depuis la racine du projet ou utiliser les wrappers `run_*.sh`.

##  Performance

| M√©trique | Valeur |
|----------|--------|
| Taille mod√®le (Q8_0) | ~7.5 GB |
| Temps d'inf√©rence | ~2-3s par requ√™te |
| Format compliance | >95% |
| Pr√©cision clinique | ~70-75% |

##  TODO

- [ ] Am√©liorer la d√©tection des n√©gations ("sans fi√®vre" mal interpr√©t√©)
- [ ] Enrichir les guidelines avec plus de cas edge
- [ ] Ajouter support multilingue (anglais m√©dical)
- [ ] Optimiser la logique de clarification dans `main.py`

##  Licence

Mod√®le de base : BioMistral-7B (Apache 2.0)  
Code : √Ä d√©finir

##  Contribution

1. Ajouter des cas dans `training/generate_finetune_dataset.py`
2. Fine-tuner avec le dataset √©tendu
3. √âvaluer avec `./run_evaluation.sh`
4. Documenter les changements

---

**Derni√®re mise √† jour** : 20 octobre 2025  
**Version** : 2.0 (structure r√©organis√©e)
